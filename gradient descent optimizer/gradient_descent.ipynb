{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'process_matrix' from '/n/home10/jmcgreivy/convex-quantum-error-correction/process_matrix.py'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import opt_einsum\n",
    "import itertools\n",
    "\n",
    "import process_matrix\n",
    "import utils\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "importlib.reload(process_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_s = 1\n",
    "q_c = 2\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalized Amplitude Damping Krauss Operators\n",
    "N = 0\n",
    "g = 0\n",
    "\n",
    "K_1 = torch.tensor([[np.sqrt(1 - N), 0],[0, np.sqrt(1 - N) * np.sqrt(1 - g)]], device = device)\n",
    "K_2 = torch.tensor([[0,np.sqrt(g*(1-N))],[0,0]], device = device)\n",
    "K_3 = torch.tensor([[np.sqrt(N)*np.sqrt(1-g), 0],[0,np.sqrt(N)]], device = device)\n",
    "K_4 = torch.tensor([[0,0],[np.sqrt(g * N), 0]], device = device)\n",
    "K = [K_1, K_2, K_3, K_4]\n",
    "\n",
    "X_E = utils.krauss_to_X_E(K, q_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_C = process_matrix.ProcessMatrix(q_s, q_c, device=\"cuda\")\n",
    "X_R = process_matrix.ProcessMatrix(q_c, q_s, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer_C = torch.optim.SGD(X_C.parameters(), lr = 0.2)\n",
    "optimizer_R = torch.optim.SGD(X_R.parameters(), lr = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Fidelity : 0.17436531305977207:  11%|â–ˆ         | 108/1000 [00:38<05:20,  2.78it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m optimizer_C\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     10\u001b[0m f_avg \u001b[38;5;241m=\u001b[39m opt_einsum\u001b[38;5;241m.\u001b[39mcontract(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmisj,misj->\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_C(), W_C)\u001b[38;5;241m.\u001b[39mreal\n\u001b[0;32m---> 11\u001b[0m X_C_identity \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39msums_to_identity(X_C())\n\u001b[1;32m     12\u001b[0m X_C_PSD \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mpositive_eigenvalues(X_C())\n\u001b[1;32m     13\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mf_avg \u001b[38;5;241m+\u001b[39m regularization\u001b[38;5;241m*\u001b[39m(X_C_identity \u001b[38;5;241m+\u001b[39m X_C_PSD)\n",
      "File \u001b[0;32m~/convex-quantum-error-correction/utils.py:28\u001b[0m, in \u001b[0;36msums_to_identity\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msums_to_identity\u001b[39m(X):\n\u001b[1;32m     27\u001b[0m     d \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], device \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 28\u001b[0m     normalization \u001b[38;5;241m=\u001b[39m (opt_einsum\u001b[38;5;241m.\u001b[39mcontract(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mijik->jk\u001b[39m\u001b[38;5;124m\"\u001b[39m,X) \u001b[38;5;241m-\u001b[39m d)\n\u001b[1;32m     29\u001b[0m     normalization \u001b[38;5;241m=\u001b[39m (normalization\u001b[38;5;241m.\u001b[39mconj() \u001b[38;5;241m*\u001b[39m normalization)\u001b[38;5;241m.\u001b[39mreal\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mcontract(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjk->\u001b[39m\u001b[38;5;124m\"\u001b[39m, normalization)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.11/site-packages/opt_einsum/contract.py:497\u001b[0m, in \u001b[0;36mcontract\u001b[0;34m(*operands, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m     full_str \u001b[38;5;241m=\u001b[39m operands[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# Build the contraction list and operand\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m operands, contraction_list \u001b[38;5;241m=\u001b[39m contract_path(\u001b[38;5;241m*\u001b[39moperands,\n\u001b[1;32m    498\u001b[0m                                            optimize\u001b[38;5;241m=\u001b[39moptimize_arg,\n\u001b[1;32m    499\u001b[0m                                            memory_limit\u001b[38;5;241m=\u001b[39mmemory_limit,\n\u001b[1;32m    500\u001b[0m                                            einsum_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    501\u001b[0m                                            use_blas\u001b[38;5;241m=\u001b[39muse_blas)\n\u001b[1;32m    503\u001b[0m \u001b[38;5;66;03m# check if performing contraction or just building expression\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gen_expression:\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.11/site-packages/opt_einsum/contract.py:253\u001b[0m, in \u001b[0;36mcontract_path\u001b[0;34m(*operands, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m num_ops \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_list)\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# Compute naive cost\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# This isnt quite right, need to look into exactly how einsum does this\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# indices_in_input = input_subscripts.replace(',', '')\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m inner_product \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m input_sets) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(indices)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    254\u001b[0m naive_cost \u001b[38;5;241m=\u001b[39m helpers\u001b[38;5;241m.\u001b[39mflop_count(indices, inner_product, num_ops, size_dict)\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# Compute the path\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.11/site-packages/opt_einsum/contract.py:253\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    247\u001b[0m num_ops \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_list)\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# Compute naive cost\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# This isnt quite right, need to look into exactly how einsum does this\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# indices_in_input = input_subscripts.replace(',', '')\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m inner_product \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m input_sets) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(indices)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    254\u001b[0m naive_cost \u001b[38;5;241m=\u001b[39m helpers\u001b[38;5;241m.\u001b[39mflop_count(indices, inner_product, num_ops, size_dict)\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# Compute the path\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "regularization = 1\n",
    "\n",
    "pbar = tqdm(range(1000))\n",
    "for epoch in pbar:    \n",
    "    #Optimize X_C:\n",
    "    W_C = (1 / (X_C().shape[0]**2)) * opt_einsum.contract(\"iljg,lmgs->misj\", X_R().detach(), X_E)\n",
    "    for _ in range(50):\n",
    "        optimizer_C.zero_grad()\n",
    "        \n",
    "        f_avg = opt_einsum.contract(\"misj,misj->\", X_C(), W_C).real\n",
    "        X_C_identity = utils.sums_to_identity(X_C())\n",
    "        X_C_PSD = utils.positive_eigenvalues(X_C())\n",
    "        l = -f_avg + regularization*(X_C_identity + X_C_PSD)\n",
    "        l.backward()\n",
    "            \n",
    "        optimizer_C.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            X_C().data = utils.make_PSD(X_C().data)\n",
    "            X_C().data = utils.make_sum_to_identity(X_C().data)\n",
    "    \n",
    "    #Optimize X_R\n",
    "    W_R = (1 / (X_C().shape[0]**2)) * opt_einsum.contract(\"misj,lmgs->iljg\", X_C().detach(), X_E)\n",
    "    for _ in range(50):        \n",
    "        # X_R Optimizing\n",
    "        optimizer_R.zero_grad()\n",
    "        \n",
    "        f_avg = opt_einsum.contract(\"iljg,iljg->\", X_R(), W_R).real\n",
    "        X_R_identity = utils.sums_to_identity(X_R())\n",
    "        X_R_PSD = utils.positive_eigenvalues(X_R())\n",
    "        l = -f_avg + regularization*(X_R_identity + X_R_PSD)\n",
    "        l.backward()\n",
    "        \n",
    "        optimizer_R.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            X_R().data = utils.make_PSD(X_R().data)\n",
    "            X_R().data = utils.make_sum_to_identity(X_R().data)\n",
    "    \n",
    "    description = f\"Avg Fidelity : {f_avg}\"\n",
    "    pbar.set_description(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-torch]",
   "language": "python",
   "name": "conda-env-.conda-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
